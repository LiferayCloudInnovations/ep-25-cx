# How to execute this helm chart:
x-invoke: |
  helm upgrade -i liferay \
    oci://us-central1-docker.pkg.dev/liferay-artifact-registry/liferay-helm-chart/liferay-default \
    --create-namespace \
    --namespace liferay-system \
    --set "image.tag=7.4.13-u132" \
    --set-file "configmap.data.license\.xml=license.xml" \
    -f helm-values/values.yaml

# How to purge this chart (including data):
x-delete: |
    helm -n liferay-system delete liferay ; k -n liferay-system delete pvc --selector "app.kubernetes.io/name=liferay-default"

x-notes: |
    # none

configmap:
  data:
    000_troubleshooting.sh: |
      #!/usr/bin/env bash

      echo "=========ENV=========="
      env | sort
    com.liferay.portal.search.elasticsearch7.configuration.ElasticsearchConfiguration.config: |
      authenticationEnabled=B"false"
      clusterName="liferay_cluster"
      httpSSLEnabled=B"false"
      indexNamePrefix="liferay-"
      networkHostAddresses=["http://liferay-default-search:9200"]
      operationMode="REMOTE"
      password="search"
      username="search"
    com.liferay.portal.store.s3.configuration.S3StoreConfiguration.config: |
      accessKey="objectstorage"
      bucketName="objectstorage"
      connectionProtocol="HTTP"
      connectionTimeout=i"20"
      corePoolSize=i"3"
      httpClientMaxConnections=i"10"
      httpClientMaxErrorRetry=i"3"
      s3Endpoint="liferay-default-objectstorage:9000"
      s3PathStyle=B"true"
      s3Region="us-west-1"
      s3StorageClass="STANDARD"
      secretKey="objectstorage"
    com.liferay.portal.trebuchet.configuration.MessageBrokerConfiguration.config: |
      host="liferay-default-rabbitmq"
      port=i"5672"
      userName="$[env:RABBITMQ_CLIENT_USERNAME]"
      password="$[env:RABBITMQ_CLIENT_PASSWORD]"
    ep25cx-log4j-ext.xml: |
      <?xml version="1.0"?>
      <Configuration strict="true">
        <Loggers>
          <Logger level="DEBUG" name="com.liferay.object.message.broker" />
          <Logger level="DEBUG" name="com.liferay.portal.trebuchet" />
        </Loggers>
      </Configuration>
    rabbitmq.conf: |
      # config
    010_init_a_default_rabbitmq_user.sh: |
      #!/usr/bin/env bash
      echo "Adding Liferay Client User ${RABBITMQ_CLIENT_USERNAME} to RabbitMQ"
      rabbitmqctl add_user "${RABBITMQ_CLIENT_USERNAME}" "${RABBITMQ_CLIENT_PASSWORD}" || true
      rabbitmqctl set_user_tags "${RABBITMQ_CLIENT_USERNAME}" 'management' || true
      rabbitmqctl set_permissions --vhost '/' "${RABBITMQ_CLIENT_USERNAME}" ".*" ".*" ".*" || true
    RABBITMQ_CLIENT_USERNAME: lfrrabbitmq
    RABBITMQ_CLIENT_PASSWORD: lfrrabbitmq
customEnv:
  x-cx-rabbitmq-demo:
  - name: LIFERAY_DISABLE_TRIAL_LICENSE
    value: "true"
  - name: LIFERAY_JPDA_ENABLED
    value: "true"
  - name: RABBITMQ_CLIENT_USERNAME
    valueFrom:
      configMapKeyRef:
        name: liferay-default
        key: RABBITMQ_CLIENT_USERNAME
  - name: RABBITMQ_CLIENT_PASSWORD
    valueFrom:
      configMapKeyRef:
        name: liferay-default
        key: RABBITMQ_CLIENT_PASSWORD
customInitContainers:
  x-cx-rabbitmq-demo:
    - containerTemplate: |
        - command:
          - bash
          - -c
          - |
            if [ -d /mnt/local/osgi/modules/ ]
            then
              mkdir -p /temp/liferay/osgi/modules/
              cp -fv /mnt/local/osgi/modules/*.jar /temp/liferay/deploy/
            fi
          image: {{ printf "%s:%s" .image.repository (.image.tag | toString) }}
          imagePullPolicy: {{ .image.pullPolicy }}
          name: liferay-deploy-modules
          volumeMounts:
          - mountPath: /temp
            name: liferay-persistent-volume
          - mountPath: /mnt/local
            name: mount-local
customVolumeMounts:
  x-cx-rabbitmq-demo:
  - mountPath: /etc/liferay/mount/files/deploy/license.xml
    name: liferay-configmap
    subPath: license.xml
  - mountPath: /mnt/local
    name: mount-local
  - mountPath: /opt/liferay/osgi/configs/com.liferay.portal.search.elasticsearch7.configuration.ElasticsearchConfiguration.config
    name: liferay-configmap
    subPath: com.liferay.portal.search.elasticsearch7.configuration.ElasticsearchConfiguration.config
  - mountPath: /opt/liferay/osgi/configs/com.liferay.portal.store.s3.configuration.S3StoreConfiguration.config
    name: liferay-configmap
    subPath: com.liferay.portal.store.s3.configuration.S3StoreConfiguration.config
  - mountPath: /opt/liferay/osgi/configs/com.liferay.portal.trebuchet.configuration.MessageBrokerConfiguration.config
    name: liferay-configmap
    subPath: com.liferay.portal.trebuchet.configuration.MessageBrokerConfiguration.config
  - mountPath: /opt/liferay/osgi/war
    name: liferay-persistent-volume
    subPath: osgi/war
  - mountPath: /usr/local/liferay/scripts/pre-configure/999_troubleshooting.sh
    name: liferay-configmap
    subPath: 000_troubleshooting.sh
  - mountPath: /opt/liferay/osgi/log4j/ep25cx-log4j-ext.xml
    name: liferay-configmap
    subPath: ep25cx-log4j-ext.xml
customVolumes:
  x-cx-rabbitmq-demo:
  - hostPath:
      path: /mnt/local
    name: mount-local
dependencies:
  database:
    portalProperties: |
      jdbc.default.driverClassName=org.postgresql.Driver
      jdbc.default.url=jdbc:postgresql://liferay-default-database:5432/lportal?useUnicode=true&characterEncoding=UTF-8&useFastDateParsing=false
      jdbc.default.username=database
      jdbc.default.password=database
    source: statefulset
    statefulset:
      env:
      - name: POSTGRES_DB
        value: lportal
      - name: POSTGRES_PASSWORD
        value: database
      - name: POSTGRES_USER
        value: database
      - name: PGUSER
        value: database
      - name: PGDATA
        value: /var/lib/postgresql/data/db
      image:
        pullPolicy: IfNotPresent
        repository: postgres
        tag: 16
      livenessProbe:
        exec:
          command: ["sh", "-c", "pg_isready -U $POSTGRES_USER -d $POSTGRES_DB"]
      ports:
      - containerPort: 5432
        name: database
        protocol: TCP
      readinessProbe:
        exec:
          command: ["sh", "-c", "pg_isready -U $POSTGRES_USER -d $POSTGRES_DB"]
      replicaCount: 1
      resources:
        limits:
          cpu: 2000m
          memory: 1Gi
        requests:
          cpu: 500m
          memory: 256Mi
      service:
        ports:
        - name: database
          port: 5432
          protocol: TCP
          targetPort: database
        type: ClusterIP
      startupProbe:
        exec:
          command: ["sh", "-c", "pg_isready -U $POSTGRES_USER -d $POSTGRES_DB"]
      storage: 1Gi
      updateStrategy:
        type: RollingUpdate
      volumeClaimTemplates:
      - metadata:
          name: liferay-database-pvc
        spec:
          accessModes:
          - ReadWriteOnce
          resources:
            requests:
              storage: 1Gi
      volumeMounts:
      - mountPath: /var/lib/postgresql/data
        name: liferay-database-pvc
  objectstorage:
    portalProperties: |
      dl.store.impl=com.liferay.portal.store.s3.S3Store
    source: statefulset
    statefulset:
      env:
      - name: MINIO_API_PORT_NUMBER
        value: "9000"
      - name: MINIO_CONSOLE_PORT_NUMBER
        value: "9001"
      - name: MINIO_DEFAULT_BUCKETS
        value: objectstorage
      - name: MINIO_REGION
        value: us-west-1
      - name: MINIO_ROOT_PASSWORD
        value: objectstorage
      - name: MINIO_ROOT_USER
        value: objectstorage
      - name: MINIO_SCHEME
        value: http
      - name: MINIO_SERVER_URL
        value: http://localhost:9000
      image:
        repository: bitnami/minio
        tag: 2024
        pullPolicy: IfNotPresent
      livenessProbe:
        httpGet:
          path: /minio/health/live
          port: api
          scheme: HTTP
      podSecurityContext:
        fsGroup: 1001
        fsGroupChangePolicy: OnRootMismatch
      ports:
      - containerPort: 9000
        name: api
        protocol: TCP
      - containerPort: 9001
        name: console
        protocol: TCP
      readinessProbe:
        httpGet:
          path: /minio/health/ready
          port: api
          scheme: HTTP
      replicaCount: 1
      resources:
        limits:
          cpu: 2000m
          memory: 1Gi
        requests:
          cpu: 500m
          memory: 256Mi
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        privileged: false
        readOnlyRootFilesystem: true
        runAsGroup: 1001
        runAsNonRoot: true
        runAsUser: 1001
        seLinuxOptions: {}
        seccompProfile:
          type: RuntimeDefault
      service:
        ports:
        - name: api
          port: 9000
          protocol: TCP
          targetPort: api
        - name: console
          port: 9001
          protocol: TCP
          targetPort: console
        type: ClusterIP
      startupProbe:
        httpGet:
          path: /minio/health/ready
          port: api
          scheme: HTTP
      storage: 1Gi
      updateStrategy:
        type: RollingUpdate
      volumeClaimTemplates:
      - metadata:
          name: liferay-objectstorage-pvc
        spec:
          accessModes:
          - ReadWriteOnce
          resources:
            requests:
              storage: 1Gi
      volumeMounts:
      - mountPath: /tmp
        name: liferay-objectstorage-pvc
        subPath: tmp-dir
      - mountPath: /opt/bitnami/minio/tmp
        name: liferay-objectstorage-pvc
        subPath: app-tmp-dir
      - mountPath: /.mc
        name: liferay-objectstorage-pvc
        subPath: app-mc-dir
      - mountPath: /bitnami/minio/data
        name: liferay-objectstorage-pvc
        subPath: data-dir
  rabbitmq:
    source: statefulset
    statefulset:
      env:
      - name: RABBITMQ_USERNAME
        value: rabbitmq
      - name: RABBITMQ_PASSWORD
        value: rabbitmq
      - name: RABBITMQ_CLIENT_USERNAME
        valueFrom:
          configMapKeyRef:
            name: liferay-default
            key: RABBITMQ_CLIENT_USERNAME
      - name: RABBITMQ_CLIENT_PASSWORD
        valueFrom:
          configMapKeyRef:
            name: liferay-default
            key: RABBITMQ_CLIENT_PASSWORD
      image:
        repository: bitnami/rabbitmq
        tag: 4.1.1-debian-12-r2
        pullPolicy: IfNotPresent
      ingress:
        enabled: true
        rules:
        - host: rabbitmq.localtest.me
          http:
            paths:
            - backend:
                service:
                  name: liferay-default-rabbitmq
                  port:
                    name: management
              path: /
              pathType: ImplementationSpecific
      livenessProbe:
        exec:
          command:
          - sh
          - -c
          - rabbitmq-diagnostics -q check_local_alarms
        initialDelaySeconds: 40
      podSecurityContext:
        fsGroup: 1001
        fsGroupChangePolicy: OnRootMismatch
      ports:
      - containerPort: 5672
        name: amqp
        protocol: TCP
      - containerPort: 15672
        name: management
        protocol: TCP
      readinessProbe:
        exec:
          command:
          - sh
          - -c
          - rabbitmq-diagnostics -q check_running
        initialDelaySeconds: 10
      replicaCount: 1
      resources:
        limits:
          cpu: 2000m
          memory: 1Gi
        requests:
          cpu: 500m
          memory: 256Mi
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        privileged: false
        readOnlyRootFilesystem: true
        runAsGroup: 1001
        runAsNonRoot: true
        runAsUser: 1001
        seLinuxOptions: {}
        seccompProfile:
          type: RuntimeDefault
      service:
        ports:
        - name: amqp
          port: 5672
          protocol: TCP
          targetPort: amqp
        - name: management
          port: 15672
          protocol: TCP
          targetPort: management
        type: ClusterIP
      startupProbe:
        exec:
          command:
          - sh
          - -c
          - rabbitmq-diagnostics -q check_port_connectivity
        initialDelaySeconds: 2
        failureThreshold: 10
        periodSeconds: 2
      storage: 1Gi
      updateStrategy:
        type: RollingUpdate
      volumeClaimTemplates:
      - metadata:
          name: liferay-rabbitmq-pvc
        spec:
          accessModes:
          - ReadWriteOnce
          resources:
            requests:
              storage: 1Gi
      volumeMounts:
      - mountPath: /bitnami/rabbitmq
        name: liferay-rabbitmq-pvc
        subPath: rabbitmq/data
      - mountPath: /opt/bitnami/rabbitmq/etc/rabbitmq
        name: liferay-rabbitmq-pvc
        subPath: rabbitmq/config
      - mountPath: /opt/bitnami/rabbitmq/.rabbitmq
        name: liferay-rabbitmq-pvc
        subPath: rabbitmq/home
      - mountPath: /opt/bitnami/rabbitmq/var/lib/rabbitmq
        name: liferay-rabbitmq-pvc
        subPath: system/var
      - mountPath: /tmp
        name: liferay-rabbitmq-pvc
        subPath: system/tmp
      - mountPath: /docker-entrypoint-initdb.d/010_init_a_default_rabbitmq_user.sh
        name: liferay-configmap
        subPath: 010_init_a_default_rabbitmq_user.sh
      volumes:
      - configMap:
          name: liferay-default
          optional: true
        name: liferay-configmap
  search:
    source: statefulset
    statefulset:
      env:
      - name: xpack.security.enabled
        value: "false"
      - name: xpack.security.transport.ssl.enabled
        value: "false"
      - name: xpack.security.http.ssl.enabled
        value: "false"
      - name: cluster.name
        value: liferay_cluster
      - name: discovery.type
        value: single-node
      - name: ES_JAVA_OPTS
        value: "-Xms256m -Xmx256m"
      - name: ELASTIC_PASSWORD
        value: search
      image:
        repository: elasticsearch
        tag: 8.17.0
        pullPolicy: IfNotPresent
      initContainers:
      - command:
        - sysctl
        - -w
        - vm.max_map_count=262144
        image: busybox:stable-uclibc
        name: increase-vm-max-map
        securityContext:
          privileged: true
      - command: ["sh", "-c", "ulimit -n 65536"]
        image: busybox:stable-uclibc
        name: increase-fd-ulimit
        securityContext:
          privileged: true
      - command:
        - sh
        - -c
        - |
          if [ ! -d ./plugins/analysis-icu ];then
            bin/elasticsearch-plugin install --batch analysis-icu analysis-kuromoji analysis-smartcn analysis-stempel
          else
            echo "Plugins already installed!"
          fi

          if [ ! -e ./_config/log4j2.properties ];then
            cp -rv ./config/* ./_config
          fi
        image: elasticsearch:8.17.0
        imagePullPolicy: IfNotPresent
        name: install-plugins
        volumeMounts:
        - mountPath: /usr/share/elasticsearch/plugins
          name: liferay-search-pvc
          subPath: plugins
        - mountPath: /usr/share/elasticsearch/_config
          name: liferay-search-pvc
          subPath: config
      livenessProbe:
        tcpSocket:
          port: search
      podSecurityContext:
        fsGroup: 1000
      ports:
      - containerPort: 9200
        name: search
        protocol: TCP
      readinessProbe:
        tcpSocket:
          port: search
      replicaCount: 1
      resources:
        limits:
          cpu: 4000m
          memory: 2Gi
        requests:
          cpu: 500m
          memory: 256Mi
      service:
        ports:
        - name: search
          port: 9200
          protocol: TCP
          targetPort: search
        type: ClusterIP
      startupProbe:
        failureThreshold: 30
        tcpSocket:
          port: search
      storage: 1Gi
      updateStrategy:
        type: RollingUpdate
      volumeClaimTemplates:
      - metadata:
          name: liferay-search-pvc
        spec:
          accessModes:
          - ReadWriteOnce
          resources:
            requests:
              storage: 1Gi
      volumeMounts:
      - mountPath: /usr/share/elasticsearch/config
        name: liferay-search-pvc
        subPath: config
      - mountPath: /usr/share/elasticsearch/data
        name: liferay-search-pvc
        subPath: data
      - mountPath: /usr/share/elasticsearch/logs
        name: liferay-search-pvc
        subPath: logs
      - mountPath: /usr/share/elasticsearch/plugins
        name: liferay-search-pvc
        subPath: plugins
ingress:
  enabled: true
  rules:
  - host: "*.dxp.localtest.me"
    http:
      paths:
      - backend:
          service:
            name: liferay-default
            port:
              name: http
        path: /
        pathType: ImplementationSpecific
portalProperties: |
  include-and-override=portal-developer.properties
  company.default.virtual.host.mail.domain=main.dxp.localtest.me
  company.default.virtual.host.name=main.dxp.localtest.me
  company.default.web.id=main.dxp.localtest.me
  web.server.display.node=true
resources:
  limits:
    cpu: 4000m
    memory: 8Gi
  requests:
    cpu: 2000m
    memory: 6Gi
